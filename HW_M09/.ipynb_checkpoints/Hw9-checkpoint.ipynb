{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3035ede8-05b9-494e-b440-a99128b8eb64",
   "metadata": {},
   "source": [
    "# Домашнє завдання №9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e636608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/f9/14/67e9b2b2379cb530c0412123a674d045eca387dfcfa7db1c0028857b0a66/tensorflow-2.16.1-cp311-cp311-macosx_12_0_arm64.whl.metadata\n",
      "  Downloading tensorflow-2.16.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Obtaining dependency information for absl-py>=1.0.0 from https://files.pythonhosted.org/packages/a2/ad/e0d3c824784ff121c03cc031f944bc7e139a8f1870ffd2845cc2dd76f6c4/absl_py-2.1.0-py3-none-any.whl.metadata\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Obtaining dependency information for astunparse>=1.6.0 from https://files.pythonhosted.org/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl.metadata\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
      "  Obtaining dependency information for flatbuffers>=23.5.26 from https://files.pythonhosted.org/packages/41/f0/7e988a019bc54b2dbd0ad4182ef2d53488bb02e58694cd79d61369e85900/flatbuffers-24.3.25-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Obtaining dependency information for gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 from https://files.pythonhosted.org/packages/fa/39/5aae571e5a5f4de9c3445dae08a530498e5c53b0e74410eeeb0991c79047/gast-0.5.4-py3-none-any.whl.metadata\n",
      "  Downloading gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Obtaining dependency information for google-pasta>=0.1.1 from https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl.metadata\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow)\n",
      "  Obtaining dependency information for h5py>=3.10.0 from https://files.pythonhosted.org/packages/8d/70/2b0b99507287f66e71a6b2e66c5ad2ec2461ef2c534668eef96c3b48eb6d/h5py-3.10.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading h5py-3.10.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/db/ed/1df62b44db2583375f6a8a5e2ca5432bbdc3edb477942b9b7c848c720055/libclang-18.1.1-py2.py3-none-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading libclang-18.1.1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
      "  Obtaining dependency information for ml-dtypes~=0.3.1 from https://files.pythonhosted.org/packages/6e/a4/6aabb78f1569550fd77c74d2c1d008b502c8ce72776bd88b14ea6c182c9e/ml_dtypes-0.3.2-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading ml_dtypes-0.3.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Obtaining dependency information for opt-einsum>=2.3.2 from https://files.pythonhosted.org/packages/bc/19/404708a7e54ad2798907210462fd950c3442ea51acc8790f3da48d2bee8b/opt_einsum-3.3.0-py3-none-any.whl.metadata\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in /Users/katerynaturuntseva/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/f3/bf/26deba06a4c910a85f78245cac7698f67cedd7efe00d04f6b3e1b3506a59/protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/katerynaturuntseva/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/katerynaturuntseva/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/katerynaturuntseva/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Obtaining dependency information for termcolor>=1.1.0 from https://files.pythonhosted.org/packages/d9/5f/8c716e47b3a50cbd7c146f45881e11d9414def768b7cd9c5e6650ec2a80a/termcolor-2.4.0-py3-none-any.whl.metadata\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/katerynaturuntseva/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/katerynaturuntseva/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/c1/0a/a8c0f403b2189f5d3e490778ead51924b56fa30a35f6e444b3702e28c8c8/grpcio-1.62.1-cp311-cp311-macosx_10_10_universal2.whl.metadata\n",
      "  Downloading grpcio-1.62.1-cp311-cp311-macosx_10_10_universal2.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
      "  Obtaining dependency information for tensorboard<2.17,>=2.16 from https://files.pythonhosted.org/packages/3a/d0/b97889ffa769e2d1fdebb632084d5e8b53fc299d43a537acee7ec0c021a3/tensorboard-2.16.2-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow)\n",
      "  Obtaining dependency information for keras>=3.0.0 from https://files.pythonhosted.org/packages/59/a8/d94e8acb59d678d908fe1db0c7ad89dfa2c2e2e529eeb3c2b3cc218a758d/keras-3.1.1-py3-none-any.whl.metadata\n",
      "  Downloading keras-3.1.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Obtaining dependency information for tensorflow-io-gcs-filesystem>=0.23.1 from https://files.pythonhosted.org/packages/3e/56/1b7ef816e448464a93da70296db237129910b4452d6b4582d5e23fb07880/tensorflow_io_gcs_filesystem-0.36.0-cp311-cp311-macosx_12_0_arm64.whl.metadata\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.36.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/katerynaturuntseva/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/katerynaturuntseva/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow)\n",
      "  Obtaining dependency information for rich from https://files.pythonhosted.org/packages/87/67/a37f6214d0e9fe57f6ae54b2956d550ca8365857f42a1ce0392bb21d9410/rich-13.7.1-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow)\n",
      "  Obtaining dependency information for namex from https://files.pythonhosted.org/packages/cd/43/b971880e2eb45c0bee2093710ae8044764a89afe9620df34a231c6f0ecd2/namex-0.0.7-py3-none-any.whl.metadata\n",
      "  Downloading namex-0.0.7-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow)\n",
      "  Obtaining dependency information for optree from https://files.pythonhosted.org/packages/cc/b8/33127d52de868d2aabc14ec6f53cb2dffafd14c5c708f50d171552a3a451/optree-0.11.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading optree-0.11.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /Users/katerynaturuntseva/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/katerynaturuntseva/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/katerynaturuntseva/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/katerynaturuntseva/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/katerynaturuntseva/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/7a/13/e503968fefabd4c6b2650af21e110aa8466fe21432cd7c43a84577a89438/tensorboard_data_server-0.7.2-py3-none-any.whl.metadata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/katerynaturuntseva/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/katerynaturuntseva/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/katerynaturuntseva/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/katerynaturuntseva/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/katerynaturuntseva/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.16.1-cp311-cp311-macosx_12_0_arm64.whl (227.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.0/227.0 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.62.1-cp311-cp311-macosx_10_10_universal2.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.10.0-cp311-cp311-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.1.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-macosx_11_0_arm64.whl (26.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp311-cp311-macosx_10_9_universal2.whl (389 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.8/389.8 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.36.0-cp311-cp311-macosx_12_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.11.0-cp311-cp311-macosx_11_0_arm64.whl (274 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: namex, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, rich, keras, tensorflow\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.9.0\n",
      "    Uninstalling h5py-3.9.0:\n",
      "      Successfully uninstalled h5py-3.9.0\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc7737c2-2912-4439-b46f-81c928702eb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fashion_mnist\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179db8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34091894-fd69-4f36-998b-72c3a96576ca",
   "metadata": {},
   "source": [
    "## Завантаження датасету"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434b01b7-b447-482e-98e8-720094341518",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9c4160-0724-4b51-87b7-17b6fb898ff7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Розмір тренувального датасету:\", len(train_data))\n",
    "print(\"Перший елемент тренувального датасету:\", train_data[0])\n",
    "print(\"Мітки тренувального датасету:\", train_labels)\n",
    "print(\"Значення мітоки: від\", min(train_labels), \"до\", max(train_labels))\n",
    "print(\"Розмір тестового датасету:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192f4277-b5bb-4ebd-b416-2b42bd401cb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_data.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca540449-ad35-4f48-b291-1cec02631537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_samples = 5\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(1, num_samples, i + 1)\n",
    "    plt.imshow(train_data[i], cmap='gray')\n",
    "    plt.title(f\"Label: {train_labels[i]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114c5246-7d2c-4698-be93-8ed599d47332",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Початкові значення параметрів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237e00b5-a5d3-44f0-97b7-3dcc76109ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_classes = 10 # загальна кількість класів, у нашому випадку це цифри від 0 до 9\n",
    "num_features = 784 # кількість атрибутів вхідного вектора 28 * 28 = 784\n",
    "\n",
    "learning_rate = 0.001 # швидкість навчання нейронної мережі\n",
    "training_steps = 20 # максимальне число епох\n",
    "batch_size = 256 # перераховувати ваги мережі ми будемо не на всій вибірці, а на її випадковій підмножині з batch_size елементів\n",
    "\n",
    "n_hidden_1 = 64 # кількість нейронів 1-го шару\n",
    "n_hidden_2 = 64 # кількість нейронів 2-го шару"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250cb0b2-bec8-41bc-a621-efc82b1d96e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Перетворюємо цілочисельні пікселі на тип float32\n",
    "x_train, x_test = np.array(train_data, np.float32), np.array(test_data, np.float32)\n",
    "\n",
    "# Перетворюємо матриці розміром 28x28 пікселів у вектор з 784 елементів\n",
    "x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])\n",
    "\n",
    "# Нормалізуємо значення пікселів\n",
    "x_train, x_test = x_train / 255., x_test / 255.\n",
    "\n",
    "# Перетворюємо цілочисельні мітки на тип float32\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')\n",
    "\n",
    "# Перетворюємо мітки в категорійний формат\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ad6eca-0f61-4b02-b083-bf8523c576f1",
   "metadata": {},
   "source": [
    "## Створення моделі"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae3c200-ea40-496d-91c9-657d2fea64a8",
   "metadata": {},
   "source": [
    "## Конфігурація №1:\n",
    "1. Кількість шарів - 2\n",
    "2. Функція активації внутрішнього шару - ReLU\n",
    "3. Кількість нейронів внутрішнього шару - 64\n",
    "4. Кількість епох - 20\n",
    "5. Розмір батчу - 256\n",
    "6. Оптимізатор - RMSprop\n",
    "7. Швидкість начання - 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42b077c-2fca-4f49-8470-99c7728ce527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(n_hidden_1, activation='relu', input_shape=(num_features,)),\n",
    "    Dense(num_classes, activation='softmax'),                    \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.RMSprop(learning_rate=learning_rate),\n",
    "    loss=losses.categorical_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bd9339-6576-4063-8901-417792aa611c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a2b866-41e3-4976-b056-c8267f33e46a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37432cef-7b2d-4445-9f9d-34b6f8e9280a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_fit(model):\n",
    "    history = model.fit(\n",
    "        partial_x_train, \n",
    "        partial_y_train, \n",
    "        epochs=training_steps,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_val, y_val)\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad82c203-6c57-4995-b809-b17ace817cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def history_visual(history):    \n",
    "    history_dict = history.history\n",
    "    loss_values = history_dict['loss']\n",
    "    val_loss_values = history_dict['val_loss']\n",
    "\n",
    "    epochs = range(1, len(history_dict['accuracy']) + 1)\n",
    "\n",
    "    plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.clf()\n",
    "    val_acc_values = history_dict['val_accuracy']\n",
    "    plt.plot(epochs, history_dict['accuracy'], 'bo', label='Training acc')\n",
    "    plt.plot(epochs, history_dict['val_accuracy'], 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d56a04-5bae-40f6-8e18-363480fdd29c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model_fit(model)\n",
    "history_visual(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efada18-6638-4832-ac20-602db31c46a6",
   "metadata": {},
   "source": [
    "## Висновок №1\n",
    "Побудована модель показала непогані результати на навчальній вибірці: точність нейромережі становить приблизно 91%. Однак, на валідаційних даних результати гірші: максимальна точність склала 88.5%. Змінимо параметри нашої моделі і проведемо другий етап експерименту."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26bd83c-8a7c-4bcd-8712-5fd326c3128b",
   "metadata": {},
   "source": [
    "## Конфігурація №2:\n",
    "1. Кількість шарів - 3\n",
    "2. Функція активації внутрішніх шарів - ReLU\n",
    "3. Кількість нейронів 1 внутрішнього шару - 256\n",
    "3. Кількість нейронів 2 внутрішнього шару - 128\n",
    "4. Кількість епох - 40\n",
    "5. Розмір батчу - 250\n",
    "6. Оптимізатор - RMSprop\n",
    "7. Швидкість начання - 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbdd79c-2d5e-4498-aca9-7763c75ec9a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001 # швидкість навчання нейронної мережі\n",
    "training_steps = 40 # число епох\n",
    "batch_size = 250 # перераховувати ваги мережі ми будемо не на всій вибірці, а на її випадковій підмножині з batch_size елементів\n",
    "n_hidden_1 = 256 # кількість нейронів 1-го шару\n",
    "n_hidden_2 = 128 # кількість нейронів 2-го шару\n",
    "\n",
    "model1 = Sequential([\n",
    "    Dense(n_hidden_1, activation='relu', input_shape=(num_features,)),\n",
    "    Dense(n_hidden_2, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax'),                    \n",
    "])\n",
    "\n",
    "model1.compile(\n",
    "    optimizer=optimizers.RMSprop(learning_rate=learning_rate),\n",
    "    loss=losses.categorical_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history1 = model_fit(model1)\n",
    "history_visual(history1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c80e37-3043-4cc8-a15f-625f93a279de",
   "metadata": {},
   "source": [
    "## Висновок №2\n",
    "Побудована модель показала кращі результати на навчальній вибірці: точність нейромережі становить приблизно 96%. На валідаційних даних  максимальна точність склала 90%. Спробуємо покращити модель за рахунок регуляризації."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa903a4-0ed2-42cb-93d2-36aee26eabfe",
   "metadata": {},
   "source": [
    "## Конфігурація №3:\n",
    "1. Кількість шарів - 3\n",
    "2. Функція активації внутрішніх шарів - ReLU\n",
    "3. Кількість нейронів 1 внутрішнього шару - 256\n",
    "3. Кількість нейронів 2 внутрішнього шару - 128\n",
    "4. Кількість епох - 40\n",
    "5. Розмір батчу - 250\n",
    "6. Оптимізатор - RMSprop\n",
    "7. Швидкість начання - 0.001\n",
    "8. Метод регуляризації - Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0e007f-d93b-4501-a9ca-f0ce0887169a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "training_steps = 40\n",
    "\n",
    "model2 = Sequential([\n",
    "    Dense(n_hidden_1, activation='relu', input_shape=(num_features,)),\n",
    "    Dropout(0.5),  \n",
    "    Dense(n_hidden_2, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax'),\n",
    "])\n",
    "\n",
    "model2.compile(\n",
    "    optimizer=optimizers.RMSprop(learning_rate=learning_rate),\n",
    "    loss=losses.categorical_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history2 = model_fit(model2)\n",
    "history_visual(history2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a9ff46-005f-4668-a385-c696f088b05f",
   "metadata": {},
   "source": [
    "## Висновок №3\n",
    "Побудована модель містить регуляризатор Dropout, який випадковим чином вимикає деякі нейрони під час навчання, тим самим роблячи мережу більш стійкою. Але модель при цьому показала дещо гірші результати на навчальній вибірці: точність нейромережі становить приблизно 89%. На валідаційних даних  максимальна точність теж склала 89%. Спробуємо покращити модель за рахунок інших методів оптимізації."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f43479-f7dd-475c-aabd-4f80b46d0fc5",
   "metadata": {},
   "source": [
    "## Конфігурація №4:\n",
    "До попередніх налаштувань використаємо планувальник швидкості навчання"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c5717f-70e0-4c97-a89a-03827f0e30cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Параметри для планувальника швидкості навчання\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True)\n",
    "\n",
    "model3 = Sequential([\n",
    "    Dense(n_hidden_1, activation='relu', input_shape=(num_features,)),\n",
    "    Dropout(0.5),  \n",
    "    Dense(n_hidden_2, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Використовуємо планувальник для оптимізатора\n",
    "optimizer = RMSprop(learning_rate=lr_schedule)\n",
    "\n",
    "model3.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history3 = model_fit(model3)\n",
    "history_visual(history3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418f10b2-ab26-4c06-897c-b52ef48da7eb",
   "metadata": {},
   "source": [
    "## Висновок №4\n",
    "Використання планувальника швидкості навчання дозволило дещо покращити модель: точність нейромережі становить приблизно 90%. На валідаційних даних  максимальна точність теж склала 90%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944b871e-2014-4d99-86af-3ed253564466",
   "metadata": {},
   "source": [
    "## Конфігурація №5:\n",
    "1. Кількість шарів - 3\n",
    "2. Функція активації внутрішніх шарів - PReLU\n",
    "3. Кількість нейронів 1 внутрішнього шару - 256\n",
    "3. Кількість нейронів 2 внутрішнього шару - 128\n",
    "4. Кількість епох - 50\n",
    "5. Розмір батчу - 250\n",
    "6. Оптимізатор - Adam\n",
    "7. Метод регуляризації - Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710f8922-9146-4d82-83eb-b6a1088045df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import PReLU\n",
    "\n",
    "training_steps = 50\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True)\n",
    "\n",
    "model4 = Sequential([\n",
    "    Dense(n_hidden_1, activation='PReLU', input_shape=(num_features,)),\n",
    "    Dropout(0.5),  \n",
    "    Dense(n_hidden_2, activation='PReLU'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Використовуємо планувальник для оптимізатора\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model4.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history4 = model_fit(model4)\n",
    "history_visual(history4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909ddbb8-c162-4fb6-80dc-7a6fb21b02a2",
   "metadata": {},
   "source": [
    "## Висновок №5\n",
    "Використання функції активації PReLU і оптимізатора Adam дозволило покращити модель: точність нейромережі становить приблизно 91%. На валідаційних даних  максимальна точність склала 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8a97b7-7a9f-4cf7-81eb-b105d6bfbc63",
   "metadata": {},
   "source": [
    "## Результати роботи моделі на тестових даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca576a9c-55f8-44dd-9eeb-4d892877995d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model4.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a613075-116b-4dde-b8f1-a198c77de80c",
   "metadata": {},
   "source": [
    "## Передбачення для тестових даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7218dc1-3079-424e-93a6-e6aa62fc6161",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = model4.predict(x_test)\n",
    "\n",
    "print(f'Predictions for the first example: {predictions[0]}')\n",
    "\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(f'Predicted classes for the first examples: {predicted_classes[:10]}')\n",
    "print(f'Real classes for the first examples: {test_labels[:10]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f02e10a-33c9-4201-8ae7-3b55e76d3841",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_samples = 5\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(2, num_samples, i + 1)\n",
    "    plt.imshow(test_data[i], cmap='gray')  \n",
    "    plt.title(f\"Label: {test_labels[i]}\")  \n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, num_samples, i + num_samples + 1)\n",
    "    plt.bar(range(10), predictions[i], color='blue', alpha=0.7)\n",
    "    plt.title(f\"Predicted: {predicted_classes[i]}\")\n",
    "    plt.xticks(range(10))\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1364aa81-a1fb-4491-b874-5a96887ad5cf",
   "metadata": {},
   "source": [
    "# Висновок:\n",
    "Нам вдалося налаштувати модель згідно з умовами завдання. В процесі оптимізації моделі змінювалися різні гіперпараметри і були обрані такі значення:\n",
    "1. Кількість шарів - 3\n",
    "2. Функція активації внутрішніх шарів - PReLU\n",
    "3. Кількість нейронів 1 внутрішнього шару - 256\n",
    "4. Кількість нейронів 2 внутрішнього шару - 128\n",
    "5. Кількість епох - 50\n",
    "6. Розмір батчу - 250\n",
    "7. Оптимізатор - Adam\n",
    "8. Метод регуляризації - Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b040d28f-1fb4-4e81-9ea6-f507cf20313f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
